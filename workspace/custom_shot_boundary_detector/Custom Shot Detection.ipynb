{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de72d3a8-7d98-4c4a-a545-2df40435ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install opencv-python\n",
    "!pip install accelerate\n",
    "!pip install sentencepiece\n",
    "!pip install protobuf\n",
    "!apt-get update\n",
    "!apt-get -y install libgl1-mesa-glx\n",
    "!apt-get -y install libglib2.0-0\n",
    "!add-apt-repository ppa:jonathonf/ffmpeg-4 -y\n",
    "!apt-get -y install ffmpeg\n",
    "!pip install ffmpeg-python pillow\n",
    "!pip install einops\n",
    "!apt-get -y install libgl1-mesa-glx\n",
    "!apt-get -y install libglib2.0-0\n",
    "!ffmpeg -hide_banner -loglevel error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1da25a-e332-4b68-9a30-f1ae348d6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, SiglipVisionModel\n",
    "import torch\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from itertools import islice\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def video_to_pil_frames(video_path):\n",
    "    print(f\"Fetching Frames: {video_path}\")\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total Frames: {total_frames}\")\n",
    "\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(frame_rgb)\n",
    "        \n",
    "        yield pil_image  # Yield one frame at a time\n",
    "\n",
    "    video.release()\n",
    "\n",
    "\n",
    "def batch_generator(iterable, batch_size):\n",
    "    iterator = iter(iterable)\n",
    "    while True:\n",
    "        batch = list(islice(iterator, batch_size))\n",
    "        if not batch:\n",
    "            break\n",
    "        yield batch\n",
    "    \n",
    "def generate_frame_vectors(model_id=\"google/siglip-base-patch16-224\",video_path=\"\"):\n",
    "    print(f\"Using checkpoint:{model_id}\")\n",
    "    model = SiglipVisionModel.from_pretrained(model_id,device_map=device)\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    start_time = time.time()\n",
    "    frames = video_to_pil_frames(video_path)\n",
    "    print(\"Processing Frames\")\n",
    "    base_file_name_with_extension = os.path.basename(video_path)\n",
    "    base_file_name, _ = os.path.splitext(base_file_name_with_extension)\n",
    "    print(\"Generating Compressed Frame Vectors\")\n",
    "    for frame in tqdm(frames,desc=\"Writing Progress\"):\n",
    "        inputs = processor(images=frame, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "        for tensor in outputs.pooler_output:\n",
    "            yield tensor.detach().flatten().reshape(1,-1)\n",
    "def compute_cosine_similarity(frames):\n",
    "    i=0\n",
    "    try:\n",
    "        next_frame = None\n",
    "        current_frame = None\n",
    "        while True:\n",
    "            if next_frame is None and current_frame is None:\n",
    "                current_frame = next(frames)\n",
    "                next_frame = next(frames)\n",
    "            similarity = torch.nn.functional.cosine_similarity(current_frame,next_frame).item()\n",
    "            yield (i,similarity)\n",
    "            current_frame = next_frame\n",
    "            next_frame = next(frames)\n",
    "            i = i + 1\n",
    "    except StopIteration:\n",
    "        print(\"End of frames Reached\")\n",
    "def generate_shots(cosine_similarities,threshold=0.9):\n",
    "    for entry in tqdm(compute_cosine_similarity(frames),desc=\"Detecting Shots\"):\n",
    "        idx,similarities = entry\n",
    "        if similarities < threshold:\n",
    "            yield idx\n",
    "def process_shot_to_tuples(shots):\n",
    "    start = 0\n",
    "    for shot in shots:\n",
    "        entry = (start,shot)\n",
    "        yield entry\n",
    "        start = shot + 1\n",
    "def write_to_csv(shots,output_path):\n",
    "    with open(output_path, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Start\",\"End\"])  # Header row\n",
    "        for row in shots:  # Iterate over the generator\n",
    "            writer.writerow(row)\n",
    "def cut_video(video_path, frame_ranges, write_video=False):\n",
    "    scene_list = []\n",
    "    scene_list_seconds = []\n",
    "    list_shot_boundary = []\n",
    "    base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    output_dir = os.path.join(os.path.dirname(video_path), base_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    probe = ffmpeg.probe(video_path)\n",
    "    video_streams = [stream for stream in probe['streams'] if stream['codec_type'] == 'video']\n",
    "    frame_rate = eval(video_streams[0]['r_frame_rate'])\n",
    "    \n",
    "    for i, (start_frame, end_frame) in enumerate(frame_ranges):\n",
    "        start_time = start_frame / frame_rate\n",
    "        start_time_seconds = convert_seconds(start_time)\n",
    "        end_time = (end_frame + 1) / frame_rate\n",
    "        end_time_seconds = convert_seconds(end_time)\n",
    "        scene_list.append((start_time,end_time))\n",
    "        scene_list_seconds.append((start_time_seconds,end_time_seconds))\n",
    "        output_file = os.path.join(output_dir, f\"{base_name}_part_{i+1}.mp4\")\n",
    "        if write_video:\n",
    "            ffmpeg.input(video_path, ss=start_time, to=end_time).output(output_file).run()\n",
    "    return scene_list,scene_list_seconds\n",
    "def overlay_markers(video_path, shot_boundaries, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for frame_idx in range(total_frames):\n",
    "        print(\"Came here\")\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        for start, end in shot_boundaries:\n",
    "            print(start,end,frame_idx)\n",
    "            if frame_idx == start or frame_idx == end:\n",
    "                height, width, _ = frame.shape\n",
    "                cv2.line(frame, (0, height//2), (width, height//2), (0, 0, 255), 5)\n",
    "                cv2.putText(frame, \"Shot Boundary\", (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "        cv2.imwrite(f\"{output_path}/frame_{frame_idx}.jpg\", frame)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f48ff2-1816-4489-a834-a40aba8420e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = generate_frame_vectors(video_path=\"Star Wars (1977).mp4\")\n",
    "similarities = compute_cosine_similarity(frames)\n",
    "shots = generate_shots(cosine_similarities=similarities)\n",
    "shot_tuples = list(process_shot_to_tuples(shots))  # Convert generator to list\n",
    "write_to_csv(shot_tuples, \"Star Wars (1977).csv\")  # Now `shot_tuples` can be used again\n",
    "overlay_markers(\"Star Wars (1977).mp4\", shot_tuples, \"Star Wars (1977)\")  # This will work as expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ee409-85a2-4aaf-b971-5586f53cbca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504784d-6b64-4435-9e03-6762008e8521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ac29c-082a-4e29-9d82-9ffb265ab030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a1edc-5c9a-4e25-9cfd-3f0ee1363c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
