{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a889fd-bb7b-4220-9957-457b9e0f9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                         \n",
      "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.11/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.11/site-packages (from opencv-python) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (0.45.2)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.5.1+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers accelerate flash_attn\n",
    "!apt-get update\n",
    "!apt-get -y install libgl1-mesa-glx\n",
    "!apt-get -y install libglib2.0-0\n",
    "!pip install opencv-python\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4089682e-5ece-4b5b-bf91-57dea0663c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlavaForConditionalGeneration(\n",
       "  (vision_tower): SiglipVisionModel(\n",
       "    (vision_model): SiglipVisionTransformer(\n",
       "      (embeddings): SiglipVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "        (position_embedding): Embedding(729, 1152)\n",
       "      )\n",
       "      (encoder): SiglipEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-25): 26 x SiglipEncoderLayer(\n",
       "            (self_attn): SiglipSdpaAttention(\n",
       "              (k_proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "              (v_proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "              (q_proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "              (out_proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): SiglipMLP(\n",
       "              (activation_fn): PytorchGELUTanh()\n",
       "              (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
       "              (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): LlavaMultiModalProjector(\n",
       "    (linear_1): Linear4bit(in_features=1152, out_features=1024, bias=True)\n",
       "    (act): GELUActivation()\n",
       "    (linear_2): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (language_model): Qwen2ForCausalLM(\n",
       "    (model): Qwen2Model(\n",
       "      (embed_tokens): Embedding(152000, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Qwen2DecoderLayer(\n",
       "          (self_attn): Qwen2Attention(\n",
       "            (q_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "            (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "            (o_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear4bit(in_features=1024, out_features=2816, bias=False)\n",
       "            (up_proj): Linear4bit(in_features=1024, out_features=2816, bias=False)\n",
       "            (down_proj): Linear4bit(in_features=2816, out_features=1024, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((1024,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((1024,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((1024,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2RotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=152000, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlavaProcessor, LlavaForConditionalGeneration\n",
    "import torch\n",
    "model_id = \"llava-hf/llava-interleave-qwen-0.5b-hf\"\n",
    "\n",
    "processor = LlavaProcessor.from_pretrained(model_id)\n",
    "\n",
    "model = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16,load_in_4bit=True)\n",
    "model.to(\"cuda\") # can also be xpu, mps, npu etc. depending on your hardware accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd3d41f-7279-4ec3-9c41-2b6850a20431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import requests\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def replace_video_with_images(text, frames):\n",
    "  return text.replace(\"<video>\", \"<image>\" * frames)\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def video_to_pil_frames(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total Frames:{total_frames}\")\n",
    "    frames = []\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        pil_image = Image.fromarray(frame_rgb)\n",
    "        frames.append(pil_image)\n",
    "    \n",
    "    video.release()\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3f6203-485d-4a29-9090-720ff77fcee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "734c7690-8803-4b0c-8295-b517575b824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames:128\n"
     ]
    }
   ],
   "source": [
    "frames = video_to_pil_frames(\"Shot_Detection/movies_to_segment_1/The Wild Bunch (1969)Autoshot/The Wild Bunch (1969)_part_4.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c821fd-ed83-4e42-8661-8d6504c2be7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>,\n",
       " <PIL.Image.Image image mode=RGB size=720x480>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc6145f-0871-40fc-a9b0-557c1e0dc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"What is this video about?\"\n",
    "toks = \"<image>\" * len(frames[:6])\n",
    "prompt = \"<|im_start|>user\"+ toks + f\"\\n{user_prompt}<|im_end|><|im_start|>assistant\"\n",
    "inputs = processor(text=prompt, images=frames[:6], return_tensors=\"pt\").to(model.device, model.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71de96fe-c74b-4e13-b2e0-07f8d5221250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "What is this video about?assistant The video appears to be a scene from a film or a television show, featuring a group of men riding horses in a desert-like setting. The men are dressed in traditional military uniforms, which are typical of the uniforms of the American military. The horses are brown and have a saddle on their back, which is typical of the saddles used by soldiers in the military. The men are moving in a coordinated manner, suggesting a sense of purpose or purposeful movement. The overall color palette of the scene is dominated by the brown and white tones of the men's uniforms, which contrast with the dusty and open landscape. The lighting is natural and diffused, with a soft glow that suggests an outdoor setting.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n",
    "print(processor.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "# The first cat is shown in a relaxed state, with its eyes closed and a content expression, while the second cat is shown in a more active state, with its mouth open wide, possibly in a yawn or a vocalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8bf7c3-067c-4dbd-95a3-2ac2ddc994fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,    872, 151646,  ...,   6243,     13, 151645]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595b5f3-34ff-4d24-8a80-047f4f3fb82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
